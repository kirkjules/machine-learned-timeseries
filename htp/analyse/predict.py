import numpy as np
import pandas as pd
from scipy.stats import randint as sp_randint
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split


# Utility function to report best scores
def report(results, n_top=3):
    for i in range(1, n_top + 1):
        candidates = np.flatnonzero(results['rank_test_score'] == i)
        for candidate in candidates:
            print("Model with rank: {0}".format(i))
            print("Mean validation score: {0:.3f} (std: {1:.3f})".format(
                  results['mean_test_score'][candidate],
                  results['std_test_score'][candidate]))
            print("Parameters: {0}".format(results['params'][candidate]))
            print("")


def random_forest(results_with_properties, train_sample_size, top=True):
    """
    A function that computes a random forest model on timeseries data defined
    by indicator values recorded against timestamps where a trade would be
    enterered, and a 'win_loss' column reflecting the ensuing result from
    entering that trade.

    Parameters
    ----------
    results_with_properties : pandas.core.frame.DataFrame
        Timeseries data containing one results 'win_loss' column and one or
        more columns containing indicator values, indexed by timestamp. The
        indicator values are calculated from the complete, raw timeseries.

    train_sample_size : int
        The sample size from the complete dataset that will be used to train
        and evaluate a random forest model.

    Returns
    -------
    pandas.core.frame.DataFrame
        A dataframe containing trades predicted to win based on a random forest
        classifier. This is a subset of 50 trades generated by the base system
        immediately following, chronologically, the training sample set.

    float
        The predicted win rate evaluated by the model being tested on a subset
        of the training sample set.
    """

    # Machine learning setup
    categorical_features = ["iky_cat_M15", "iky_cat_H1"]
    categorical_transformer = ColumnTransformer(
        transformers=[
            ("iky_cat", OneHotEncoder(handle_unknown="ignore"),
             categorical_features)], remainder="passthrough")

    train = results_with_properties[0:train_sample_size].copy()
    X_train, X_test, y_train, y_test = train_test_split(
        train.drop("win_loss", axis=1), train["win_loss"], random_state=42,
        shuffle=True, test_size=0.1)

    clf = Pipeline(
        steps=[("cat_trans", categorical_transformer),
               ("random_forest", RandomForestClassifier(n_estimators=100))])

    # clf.fit(X_train, y_train)
    # all_feature_score = clf.score(X_test, y_test)
    # print("\nAll feature model score: %.3f\n" % all_feature_score)

    # specify parameters and distributions to sample from
    param_dist = {"random_forest__max_depth": [3, None],
                  "random_forest__max_features": sp_randint(1, 11),
                  "random_forest__min_samples_split": sp_randint(2, 11),
                  "random_forest__bootstrap": [True, False],
                  "random_forest__criterion": ["gini", "entropy"]}

    n_iter_search = 20
    random_search = RandomizedSearchCV(clf, param_distributions=param_dist,
                                       n_iter=n_iter_search, cv=5, iid=False)

    random_search.fit(X_train, y_train)
    # all_feature_score = np.round(random_search.best_score_, decimals=2)
    all_feature_score = np.round(
        random_search.score(X_test, y_test), decimals=2)

    if top:

        feature_dictionary = {}
        for feature in list(
          zip(X_train,
              random_search.best_estimator_.steps[1][1].feature_importances_)):
            feature_dictionary[feature[0]] = feature[1]

        features = pd.Series(feature_dictionary)
        top_features = list(features.nlargest(n=10, keep="first").index)
        top_features.append("win_loss")

        top_train = train[top_features].copy()
        X_train, X_test_top, y_train, y_test = train_test_split(
            top_train.drop("win_loss", axis=1), top_train["win_loss"],
            random_state=42, shuffle=False, test_size=0.1)

        top_categorical_features = []
        for feature in top_features:
            if "iky_cat" in feature:
                top_categorical_features.append(feature)

        # del clf
        # del categorical_transformer
        if len(categorical_features) > 0:
            top_categorical_transformer = ColumnTransformer(
                transformers=[
                    ("iky_cat", OneHotEncoder(handle_unknown="ignore"),
                     top_categorical_features)], remainder="passthrough")
            top_clf = Pipeline(
                steps=[
                    ("cat_trans", top_categorical_transformer),
                    ("random_forest", RandomForestClassifier(n_estimators=100))
                ])
        else:
            top_clf = Pipeline(
                steps=[
                    ("random_forest", RandomForestClassifier(n_estimators=100))
                ])

        # top_clf.fit(X_train, y_train)
        # top_feature_score = top_clf.score(X_test_top, y_test)
    # print("\nTop feature model score: %.3f\n" % clf.score(X_test, y_test))

        top_random_search = RandomizedSearchCV(
            top_clf, param_distributions=param_dist, n_iter=n_iter_search,
            cv=5, iid=False)

        top_random_search.fit(X_train, y_train)
        # top_feature_score = np.round(
        #    top_random_search.best_score_, decimals=2)
        top_feature_score = np.round(
            top_random_search.score(X_test_top, y_test), decimals=2)

    # Test random forest
    if top_feature_score > all_feature_score:
        pred_test = top_random_search.predict(X_test_top)
    else:
        pred_test = random_search.predict(X_test)

    pred_results = pd.crosstab(
        y_test, pred_test, rownames=["Actual"], colnames=["Predicted"])

    try:
        pred_win_rate = np.round(
            (pred_results.loc[1, 1] / pred_results[1].sum() * 100), decimals=2)
    except KeyError:
        return None, "NA", all_feature_score, top_feature_score

    if pred_results[1].sum() < 5:
        return None, "NA", all_feature_score, top_feature_score

    # This is the important threshold, not the original system win rate.
    if pred_win_rate < 70.:
        return None, pred_win_rate, all_feature_score, top_feature_score

    # print(pred_results[1].sum()) - not significant
    live = results_with_properties[train_sample_size:].copy()

    if top is True and top_feature_score > all_feature_score:
        X_live = live[top_features].drop("win_loss", axis=1)
        pred_live = top_random_search.predict(X_live)
    else:
        X_live = live.drop("win_loss", axis=1)
        pred_live = random_search.predict(X_live)

    y_live = live["win_loss"].copy()

    pred_df = pd.DataFrame(
        columns=["win_loss"], data=pred_live, index=y_live.index,
        copy=True)

    pred_win_df = pred_df[pred_df["win_loss"] == 1].copy()

    return pred_win_df, pred_win_rate, all_feature_score, top_feature_score
